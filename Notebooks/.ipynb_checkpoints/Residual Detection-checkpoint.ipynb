{
 "metadata": {
  "name": "",
  "signature": "sha256:3e18e83afb8e3db2ffe951ff4c2f89a2effbf42324586a1acbeb9140917faea5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After the model has been fit to and subtracted out, the final step is detecting residuals. There are a lot of ways to do this, so I'm going to try to do a few of them here to see how they shake out. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Load Data\n",
      "First thing's first load in the data. I'm going to load in the data from one of my sample runs, in the form of a numpy array. This is the form that my data comes out in the code after a fit is performed. It's possible to transform it into a fits image, and I actually do that later in this notebook. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#remember to change this on your machine. \n",
      "directory = '/home/sean/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/'\n",
      "filename = 'CFHTLS_072_2003'\n",
      "import numpy as np\n",
      "import os\n",
      "#from time import time\n",
      "#np.random.seed(int(time()))\n",
      "\n",
      "#filename = np.random.choice(os.listdir(directory))\n",
      "filename = directory+filename"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "from IPython.core.pylabtools import figsize\n",
      "figsize(14,8)\n",
      "\n",
      "#load and plot\n",
      "image  = np.loadtxt(filename, delimiter = ',')\n",
      "im = plt.imshow(image)\n",
      "plt.colorbar(im)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "[Errno 2] No such file or directory: '/home/mclaughlin6464/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/CFHTLS_072_2003'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-cfc3b4e2f1c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#load and plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimage\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/numpy/lib/npyio.pyc\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'U'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/mclaughlin6464/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/CFHTLS_072_2003'"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import deepcopy\n",
      "std = image.std()\n",
      "mean = image.mean()\n",
      "threshold = mean+1*std #if there are pixels where the value is 3 std's greater than the mean\n",
      "\n",
      "threshImage = deepcopy(image)\n",
      "threshImage[threshImage<threshold] = 0 #assign all negative values to 0\n",
      "\n",
      "print 'There are at least 10 pixels 2 sigma above backgroud: %s'%(np.sum(image>threshold)>10) #10 pixels over the threshold\n",
      "im = plt.imshow(threshImage)\n",
      "plt.colorbar(im)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pretty clear, and there are results for an increase of several standard deviations too. The trouble is you have to identify that the pixels over threshold are in fact clumped together. This can be done with any unsupervised learning thing like sklearn. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cluster import DBSCAN\n",
      "agg = DBSCAN(eps = 2, min_samples = 6)\n",
      "\n",
      "data = []\n",
      "img_y, img_x = image.shape\n",
      "for x in xrange(img_x):\n",
      "    for y in xrange(img_y):\n",
      "        if image[y,x]>threshold:\n",
      "            data.append([y,x])\n",
      "            \n",
      "data = np.array(data)\n",
      "\n",
      "agg.fit(data)\n",
      "labels = agg.labels_\n",
      "print '%d clusters identified.'%len(set(labels))\n",
      "if -1 in labels:\n",
      "    print 'Noise Cluster identified and not plotted.'\n",
      "colors = ['r', 'b', 'g', 'm', 'c', 'y', 'k']\n",
      "for i, color in enumerate(colors):\n",
      "    d =data[labels ==i]\n",
      "    s = []\n",
      "    for idx in d:\n",
      "        val = (image[tuple(idx)]-threshold)*15\n",
      "        s.append(val)\n",
      "    plt.scatter(d[:,1], img_y-d[:,0], color = color, s = s)\n",
      "    \n",
      "plt.xlim(0, img_x)\n",
      "plt.ylim(0, img_y)\n",
      "figsize(12,12)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So the clustering algorithm identified 3 clusters in the image, each corresponding to a piece of the lens. Occasionally, if a 'blip' is too small, the clustering algorithm will peg it as noise and not plot it. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###SExtractor\n",
      "So that worked alright, but I want to compare to how SExtractor handles it. I'll run sextractor on it below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#save the image to file locally as a fits file. \n",
      "figsize(14,8)\n",
      "import pyfits\n",
      "import os\n",
      "hdu = pyfits.PrimaryHDU(image)\n",
      "fname = 'image.fits'\n",
      "#uncomment if there is an error. I don't want to delete stuff in your directory without you acknowledging it manually. \n",
      "if fname in os.listdir(os.getcwd()):\n",
      "   os.remove(fname)\n",
      "hdu.writeto(fname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, I have to copy the sextractor params over to run in this directory. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "cp /usr/local/share/sextractor/default* ."
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I'm modifying the param file to get the x and y locations of the objects. There is a wealth of other information I could get but I'm not worried about any of that now. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = []\n",
      "#I'm only interested in identifyin the objects\n",
      "params = set(['X_IMAGE', 'Y_IMAGE'])\n",
      "with open('default.param') as f:\n",
      "    for line in f:\n",
      "        var = line[1:line.find(' ')].strip()\n",
      "        if var in params:\n",
      "            line = line[1:]\n",
      "        lines.append(line)\n",
      "        \n",
      "paramText = ''.join(lines)\n",
      "with open('default.param', 'w') as f:\n",
      "    f.write(paramText)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "sex image.fits -CHECKIMAGE_TYPE OBJECTS"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#the output file for sextractor is formatted in an extremely unusual way. \n",
      "#it makes it difficult to read in, so I have to do this nonsense to get the coordinates out. \n",
      "coords = []\n",
      "with open('test.cat') as f:\n",
      "    for line in f:\n",
      "        if line[0] =='#':\n",
      "            continue \n",
      "        line = line.strip()\n",
      "        splitLine = line.split(' ')\n",
      "        out = []\n",
      "        for x in splitLine:\n",
      "            if x:\n",
      "                out.append(float(x))\n",
      "        coords.append(out)\n",
      "        \n",
      "#sextractor also uses a 1-based indexing system for god knows what reason. \n",
      "coords = np.array(coords)-1 \n",
      "\n",
      "#open the check image which holds only the object, and plot. \n",
      "checkImage = pyfits.open('check.fits')\n",
      "data = checkImage[0].data\n",
      "im = plt.imshow(data)\n",
      "plt.colorbar(im)\n",
      "\n",
      "plt.scatter(coords[:,0], coords[:,1], color = 'm', s= 50, label = 'Objs')\n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sextractor got the same objects as I did, but obviously got them much better than me. There is also a lot more available to do from sextractor, and I don't know what of it's many tools will be useful. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Improvements on my extractor\n",
      "There is a lot that SExtractor has to offer. However, it may be a little bit too much for what I'm trying to develop. What I'm interested in doing is developing a simple series of tests that will determine if something probably is a lens or not. I can add, remove and move around any of them as I go along, but I'll start with:\n",
      "\n",
      "-number of objects >= 2.\n",
      "\n",
      "-Centers of light distributions are approximately equidistant from the center of the image. \n",
      "\n",
      "-The major axes of the distributions are roughly perpendicular to the line toward the center of the image.\n",
      "\n",
      "Below I reenter the data before starting. I won't do an nObjects count because I kind of already did that with my clustering algorithm. I will however gather the clusters in a Residual object, allowing me to store data in the same place for each one. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Residual(object):\n",
      "    \n",
      "    def __init__(self, pointsSet, key, image, color):\n",
      "        \n",
      "        self.pointsSet = pointsSet #a set of all points in tuples, for membership and accessing image pixels\n",
      "        self.points = np.array(list(pointsSet)) #an np array of points.  \n",
      "        \n",
      "        self.key = key# the key to access the Residual in the dictionary, 'Noise' or 0,1,2...\n",
      "        if self.key == -1:\n",
      "            self.key = 'Noise'\n",
      "        self.image = image # a reference to the image this object comes from\n",
      "        self.color = color #the color to use in plotting, for consistency. \n",
      "        \n",
      "        self.center, self.dist, self.vect, self.theta = self._findMoments() #find the center of this residual and it's distance from the center\n",
      "        self.a, self.b = self.vect\n",
      "        \n",
      "    def __contains__(self, item):\n",
      "        return self.pointsSet.__contains__(item)\n",
      "    \n",
      "    def __iter__(self):\n",
      "        return self.pointsSet.__iter__()\n",
      "      \n",
      "    def getXY(self):#returns the x and y as separate arrays, for plotting\n",
      "        return self.points[:,1], self.points[:,0]\n",
      "    \n",
      "    def _findMoments(self): #find the moments of the distribution\n",
      "        Ix = Iy = Ixx = Iyy = Ixy = I = long(0)\n",
      "        \n",
      "        for idx in self.pointsSet:\n",
      "            y,x = idx\n",
      "            val = self.image[idx]\n",
      "            I+=val\n",
      "            Ix+=x*val\n",
      "            Iy+=y*val\n",
      "            Ixx+=x*x*val\n",
      "            Iyy+=y*y*val\n",
      "            Ixy+=x*y*val\n",
      "            \n",
      "        xmean = Ix/I\n",
      "        ymean = Iy/I\n",
      "              \n",
      "        img_y, img_x = self.image.shape\n",
      "        imgCenterY, imgCenterX = img_y/2.0, img_x/2.0\n",
      "        \n",
      "        #the distane of the center of the light from the center of the distribution\n",
      "        dist = np.sqrt((xmean-imgCenterX)**2+(ymean-imgCenterY)**2)\n",
      "        \n",
      "        Uxx = Ixx/I-xmean**2\n",
      "        Uyy = Iyy/I-ymean**2\n",
      "        Uxy = Ixy/I-xmean*ymean\n",
      "        \n",
      "        theta = .5*np.arctan(2.0*Uxy/(Uxx-Uyy))\n",
      "        \n",
      "        lambda1 = .5*(Uxx+Uyy)+.5*np.sqrt(4*Uxy**2+(Uxx-Uyy)**2)\n",
      "        lambda2 = .5*(Uxx+Uyy)-.5*np.sqrt(4*Uxy**2+(Uxx-Uyy)**2)\n",
      "        \n",
      "        return (ymean, xmean), dist, (np.sqrt(lambda1), np.sqrt(lambda2)), theta \n",
      "    \n",
      "    def isNoise(self):\n",
      "        return self.key == 'Noise'\n",
      "                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I've made the object, now let's apply it to our image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image  = np.loadtxt(filename, delimiter = ',')\n",
      "std = image.std()\n",
      "mean = image.mean()\n",
      "nSigma = 1\n",
      "threshold = mean+nSigma*std #if there are pixels where the value is n std'\n",
      "\n",
      "agg = DBSCAN(eps = 2, min_samples = 6)\n",
      "\n",
      "#gather the x y data\n",
      "data = []\n",
      "img_y, img_x = image.shape\n",
      "for x in xrange(img_x):\n",
      "    for y in xrange(img_y):\n",
      "        if image[y,x]>threshold:\n",
      "            data.append([y,x])\n",
      "            \n",
      "data = np.array(data)\n",
      "\n",
      "agg.fit(data)\n",
      "labels = agg.labels_\n",
      "\n",
      "#gather the clusters into the dictionary\n",
      "nClusters = len(set(labels))\n",
      "clustRange = xrange(nClusters)\n",
      "if -1 in labels:\n",
      "#noise cluster identified\n",
      "    clustRange = xrange(-1, nClusters-1)\n",
      "\n",
      "colors = ['r', 'b', 'g', 'm', 'c', 'y', 'k']\n",
      "residuals = {}\n",
      "for i, color in zip(clustRange, colors):\n",
      "    #gather the points by cluster and create their cluster object. \n",
      "    cluster = set()\n",
      "    d = data[labels == i]\n",
      "\n",
      "    for idx in d:\n",
      "        cluster.add(tuple(idx))\n",
      "      \n",
      "    if i == -1:\n",
      "        residuals['Noise'] = Residual(cluster, 'Noise',image, color)\n",
      "    else:\n",
      "        residuals[i] =Residual(cluster, i, image, color)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And now, plot, for santy's sake. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threshImage = np.where(image>threshold, image, 0)\n",
      "figsize(16,8)\n",
      "plt.subplot(121)\n",
      "plt.title('Caught Pixels')\n",
      "plt.imshow(threshImage)\n",
      "\n",
      "plt.subplot(122)   \n",
      "\n",
      "for residual in residuals.itervalues():\n",
      "    plt.subplot(122)\n",
      "    if residual.isNoise():\n",
      "        continue\n",
      "    \n",
      "    s = []\n",
      "    for idx in residual:\n",
      "        val = (image[idx]-threshold)*15\n",
      "        s.append(val)\n",
      "    \n",
      "    xx, yy = residual.getXY() \n",
      "    plt.scatter(xx, img_y-yy, color = residual.color, s = s)\n",
      "    \n",
      "    plt.subplot(121)\n",
      "    plt.xlim(0,img_x )\n",
      "    plt.ylim(img_y, 0)\n",
      "    yc, xc = residual.center\n",
      "    a, b = residual.a, residual.b\n",
      "    #Theta seems to be coming out wrong. \n",
      "    theta = -1*residual.theta\n",
      "    \n",
      "    plt.scatter(xc, yc, color = 'k')\n",
      "    plt.plot((xc - a * np.sin(theta), xc + a * np.sin(theta)), \\\n",
      "               (yc - a * np.cos(theta), yc + a * np.cos(theta)), color='g')\n",
      "\n",
      "    plt.plot((xc - b * np.cos(theta), xc + b * np.cos(theta)), \\\n",
      "              (yc + b * np.sin(theta), yc - b * np.sin(theta)), color='m')\n",
      "    imgCx, imgCy = (img_x-1)/2.0, (img_y-1)/2.0\n",
      "    plt.plot((xc, imgCx), (yc, imgCy), color = 'r')\n",
      "   \n",
      "plt.subplot(122)  \n",
      "plt.xlim(0, img_x)\n",
      "plt.ylim(0, img_y)\n",
      "plt.title('Clusters Redone')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Everything works as expected, so let's begin designing a pipeline. The first factor of interest will be the number of identified objects. The images will be subdivided into cases where:\n",
      "\n",
      "nObjects = 0: Not a lens, and nothing to check anyway\n",
      "\n",
      "nObjects = 1: Possibly a lens. Possibly a complete \"ring\", or one stray arc. Test for both cases.\n",
      "\n",
      "nObjects = 2: Multiple causes. Ideally, it'd be 2 objects on either side of one another from the lensed image. It's possible that they could be on the same side as one another, in which case check for comparable distance. \n",
      "\n",
      "nObjects >= 3: Similar to 2. Check if they are comparable distances from the center. Also, check that the major axes are all perpindicular to the line toward the center of the image. \n",
      "\n",
      "I'll design that below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def checkLens(residuals):\n",
      "    \n",
      "    nObjects = len(residuals)\n",
      "    if 'Noise' in residuals:\n",
      "        nObjects -=1 #ignore noise\n",
      "        \n",
      "    if nObjects == 0:\n",
      "        return False \n",
      "    \n",
      "    if nObjects == 1:\n",
      "        residual = residuals[0]\n",
      "        center_difference = 3 #the distance from the center the ring is allowed to be. \n",
      "        if residual.dist<center_difference:\n",
      "            return True\n",
      "        \n",
      "    if nObjects ==2:\n",
      "        #compare slopes that connect the centers with the slopes of the major axes\n",
      "        obj1 = residuals[0]\n",
      "        obj2 = residuals[1]\n",
      "        \n",
      "        c1y, c1x = obj1.center\n",
      "        c2y, c2x = obj2.center\n",
      "        \n",
      "        imgCy, imgCx = img.shape[0]/2.0, img.shape[1]/2.0\n",
      "        \n",
      "        slope1 = (c1y-imgCy)/float(c1x-imgCx)\n",
      "        slope2 = (c2y-imgCy)/float(c2x-imgCx)\n",
      "        #might have to check for divide by zeroes and all that\n",
      "        acrossOneAnother= slope1*slope2<0 and .1<abs(slope1/slope2)<10 #opposite sides and comparable slopes\n",
      "        \n",
      "        properlyOriented = 0 #if the axes are parralel/perpendicular to the line toward the center. \n",
      "        for obj,slope in zip((obj1, obj2), (slope1, slope2)):\n",
      "            a, b = obj.a, obj.b\n",
      "            #Theta seems to be coming out wrong. \n",
      "            theta = -1*obj.theta\n",
      "\n",
      "            axesSlope = 1/np.tan(theta)\n",
      "            #maybe i should be checking specifically the major axis, but they seem almost interchangeable\n",
      "            properlyOriented+= 1 if .1<abs(axesSlope/slope)<10 else 0 #if the abs  of the slopes is comparable, parralel or perp\n",
      "            \n",
      "        enoughPerp = properlyOriented==2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}