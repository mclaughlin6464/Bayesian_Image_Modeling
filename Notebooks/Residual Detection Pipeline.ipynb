{
 "metadata": {
  "name": "",
  "signature": "sha256:3fec0bb8e82c1979c714d3c805b1d481902ef61db58e2b1d7749ebf829f0013c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below is my proposed lens-detection pipeline. I've written it as several functions and objects. \n",
      "\n",
      "###Residual Object\n",
      "First thing's first is the Residual object. It holds all the information pertinent to a cluster that was identified in the image."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import os\n",
      "from matplotlib import pyplot as plt\n",
      "%matplotlib inline\n",
      "from IPython.core.pylabtools import figsize\n",
      "from sklearn.cluster import DBSCAN\n",
      "\n",
      "class Residual(object):\n",
      "    \n",
      "    def __init__(self, pointsSet, key, image, color):\n",
      "        \n",
      "        self.pointsSet = pointsSet #a set of all points in tuples, for membership and accessing image pixels\n",
      "        self.points = np.array(list(pointsSet)) #an np array of points.  \n",
      "        \n",
      "        self.key = key# the key to access the Residual in the dictionary, 'Noise' or 0,1,2...\n",
      "        if self.key == -1:\n",
      "            self.key = 'Noise'\n",
      "        self.image = image # a reference to the image this object comes from\n",
      "        self.color = color #the color to use in plotting, for consistency. \n",
      "        \n",
      "        self.center, self.dist, self.vect, self.theta = self._findMoments() #find the center of this residual and it's distance from the center\n",
      "        self.a, self.b = self.vect\n",
      "        \n",
      "        #NOTE can calcluate slope to center of image here\n",
      "        \n",
      "    def __contains__(self, item): #for if point in Residual checks\n",
      "        return self.pointsSet.__contains__(item)\n",
      "    \n",
      "    def __iter__(self): #return the tuples in an iterator, so the values can be accessed in the image. \n",
      "        return self.pointsSet.__iter__()\n",
      "      \n",
      "    def getXY(self):#returns the x and y as separate arrays, for plotting\n",
      "        return self.points[:,1], self.points[:,0]\n",
      "    \n",
      "    def _findMoments(self): #find the moments of the distribution\n",
      "        Ix = Iy = Ixx = Iyy = Ixy = I = long(0)\n",
      "        \n",
      "        for idx in self.pointsSet:\n",
      "            y,x = idx\n",
      "            val = self.image[idx]\n",
      "            I+=val\n",
      "            Ix+=x*val\n",
      "            Iy+=y*val\n",
      "            Ixx+=x*x*val\n",
      "            Iyy+=y*y*val\n",
      "            Ixy+=x*y*val\n",
      "            \n",
      "        xmean = Ix/I\n",
      "        ymean = Iy/I\n",
      "              \n",
      "        img_y, img_x = self.image.shape\n",
      "        imgCenterY, imgCenterX = img_y/2.0, img_x/2.0\n",
      "        \n",
      "        #the distane of the center of the light from the center of the distribution\n",
      "        dist = np.sqrt((xmean-imgCenterX)**2+(ymean-imgCenterY)**2)\n",
      "        \n",
      "        Uxx = Ixx/I-xmean**2\n",
      "        Uyy = Iyy/I-ymean**2\n",
      "        Uxy = Ixy/I-xmean*ymean\n",
      "        \n",
      "        theta = .5*np.arctan(2.0*Uxy/(Uxx-Uyy))\n",
      "        \n",
      "        lambda1 = .5*(Uxx+Uyy)+.5*np.sqrt(4*Uxy**2+(Uxx-Uyy)**2)\n",
      "        lambda2 = .5*(Uxx+Uyy)-.5*np.sqrt(4*Uxy**2+(Uxx-Uyy)**2)\n",
      "        \n",
      "        return (ymean, xmean), dist, (np.sqrt(lambda1), np.sqrt(lambda2)), theta \n",
      "    \n",
      "    def isNoise(self): #The clustering algorithm I'm using identifies noise clusters. \n",
      "        return self.key == 'Noise'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function below takes a filename and loads in the numpy array. It creates a dictionary of Residual objects, of the clusters in the image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def makeResidualsDict(filename): #makes a dict of Residual objects from a filename\n",
      "    \n",
      "    image  = np.loadtxt(filename, delimiter = ',')\n",
      "    std = image.std()\n",
      "    mean = image.mean()\n",
      "    nSigma = 1\n",
      "    threshold = mean+nSigma*std #if there are pixels where the value is n std'\n",
      "     \n",
      "    #gather the x y data\n",
      "    data = []\n",
      "    img_y, img_x = image.shape\n",
      "    for x in xrange(img_x):\n",
      "        for y in xrange(img_y):\n",
      "            if image[y,x]>threshold:\n",
      "                data.append([y,x])\n",
      "                \n",
      "    data = np.array(data)\n",
      "    \n",
      "    #cluster the points\n",
      "    agg = DBSCAN(eps = 2, min_samples = 6)\n",
      "\n",
      "    agg.fit(data)\n",
      "    labels = agg.labels_\n",
      "    \n",
      "    #gather the clusters into the dictionary\n",
      "    nClusters = len(set(labels))\n",
      "    clustRange = xrange(nClusters)\n",
      "    if -1 in labels:\n",
      "    #noise cluster identified\n",
      "        clustRange = xrange(-1, nClusters-1)\n",
      "    \n",
      "    colors = ['r', 'b', 'g', 'm', 'c', 'y', 'k']\n",
      "    residuals = {}\n",
      "    for i, color in zip(clustRange, colors):\n",
      "        #gather the points by cluster and create their cluster object. \n",
      "        cluster = set()\n",
      "        d = data[labels == i]\n",
      "    \n",
      "        for idx in d:\n",
      "            cluster.add(tuple(idx))\n",
      "        \n",
      "        #create the objects and put them in the dictionary\n",
      "        if i == -1:\n",
      "            residuals['Noise'] = Residual(cluster, 'Noise',image, color)\n",
      "        else:\n",
      "            residuals[i] =Residual(cluster, i, image, color)\n",
      "            \n",
      "    return residuals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###checkLens Pipeline\n",
      "Below I work out the pipeline to determine if a residuals dictionary represents a lens or not. The pipeline's layout is as follows.\n",
      "\n",
      "The first subdivision is by the number of objects identified. \n",
      "\n",
      "nObjects = 0: Not a lens, and nothing to check anyway\n",
      "\n",
      "nObjects = 1: Possibly a lens. Possibly a complete \"ring\", or one stray arc. Test for both cases.\n",
      "\n",
      "nObjects = 2: Multiple causes. Ideally, it'd be 2 objects on either side of one another from the lensed image. It's possible that they could be on the same side as one another, in which case check for comparable distance. Also check the perpendiculatiry of the axes.\n",
      "\n",
      "nObjects >= 3: Similar to 2. Check if they are comparable distances from the center. Also, check that the major axes are all perpindicular to the line toward the center of the image. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def checkLens(residuals):\n",
      "    \n",
      "    nObjects = len(residuals)\n",
      "    if 'Noise' in residuals:\n",
      "        nObjects -=1 #ignore noise\n",
      "        \n",
      "    if nObjects <1:\n",
      "        return False \n",
      "    \n",
      "    image = residuals[0].image\n",
      "    \n",
      "    if nObjects == 1:\n",
      "        residual = residuals[0]\n",
      "        center_difference = 3 #the distance from the center the ring is allowed to be. \n",
      "        if residual.dist<=center_difference:\n",
      "            return True\n",
      "        \n",
      "        return False\n",
      "            \n",
      "    else: #nObjects >=2\n",
      "        \n",
      "        enoughPerp = False #enough of the objects have axes perpendicular to the line to the center\n",
      "        closeTogether = False# the objects are a comparable distance from the center\n",
      "        imgCy, imgCx = (image.shape[0]-1)/2.0, (image.shape[1]-1)/2.0\n",
      "        \n",
      "        objs = [residuals[i] for i in xrange(nObjects)]\n",
      "        #the slope of the line connecting the center of the object to the center of the image.\n",
      "        slopes = [(obj.center[0]-imgCy)/float(obj.center[1]-imgCx) for obj in objs]\n",
      "        properlyOriented = 0\n",
      "        for obj, slope in zip(objs, slopes):\n",
      "            \n",
      "            theta = -1*obj.theta #seems to come out negative; not sure if it's a plotting error or what. \n",
      "            axesSlope = 1/np.tan(theta)\n",
      "            #maybe I should be specifically checking the major axis\n",
      "            properlyOriented+= 1 if .1<abs(axesSlope/slope)<10 else 0 #comparable in magnitude\n",
      "            \n",
      "        enoughPerp = properlyOriented >1 #if there is more than one lined up well\n",
      "        #the differences of the distances of the objects to their centers\n",
      "        diffs = []\n",
      "        for i, obj in enumerate(objs):\n",
      "            for obj2 in objs[i+1:]:\n",
      "                diffs.append(abs(obj.dist-obj2.dist))\n",
      "                \n",
      "        diffs = np.array(diffs)\n",
      "        #if the average distance from one another is small\n",
      "        closeTogether = diffs.mean()<3 #arbitrary number. \n",
      "        \n",
      "        if nObjects == 2: #special case\n",
      "            slope1, slope2 = slopes[0], slopes[1]\n",
      "            ratio = slope1/slope2\n",
      "            #i'm not sure if you want a positive slope or allow a slight negative difference, for a 'kink'\n",
      "            \n",
      "            #check if the objects are across the center from one another. \n",
      "            acrossOneAnother= ratio>-.2 and .1<abs(ratio)<10 #opposite sides and comparable slopes\n",
      "            return (acrossOneAnother and enoughPerp) or (acrossOneAnother and closeTogether \\\n",
      "                        or enoughPerp and closeTogether)#any 2\n",
      "        \n",
      "        return closeTogether and enoughPerp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And last but not least, a plotting function to show the image, the clusters, and the axes/lines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plotResiduals(residuals): #plots all info for the residual. \n",
      "    image = residuals[0].image\n",
      "    threshold = image.mean()+image.std()\n",
      "    threshImage = np.where(image>threshold, image, 0) #cut out what was below threshold\n",
      "    figsize(16,8)\n",
      "    plt.subplot(121)\n",
      "    plt.title('Caught Pixels')\n",
      "    plt.imshow(threshImage)\n",
      "    \n",
      "    plt.subplot(122)   \n",
      "    \n",
      "    for residual in residuals.itervalues():\n",
      "        img_y, img_x = image.shape\n",
      "        plt.subplot(122)\n",
      "        if residual.isNoise(): #don't plot noise\n",
      "            continue\n",
      "        \n",
      "        s = []#list of sizes of the points in the scatter plot\n",
      "        for idx in residual:\n",
      "            val = (image[idx]-threshold)*15\n",
      "            s.append(val)\n",
      "        \n",
      "        xx, yy = residual.getXY() \n",
      "        plt.scatter(xx, img_y-yy, color = residual.color, s = s)\n",
      "        \n",
      "        plt.subplot(121)\n",
      "        plt.xlim(0,img_x )\n",
      "        plt.ylim(img_y, 0)\n",
      "        yc, xc = residual.center\n",
      "        a, b = residual.a, residual.b\n",
      "        #Theta seems to be coming out wrong. I don't know if it's the plot being weird or what. \n",
      "        theta = -1*residual.theta\n",
      "        \n",
      "        plt.scatter(xc, yc, color = 'k')\n",
      "        plt.plot((xc - a * np.sin(theta), xc + a * np.sin(theta)), \\\n",
      "                   (yc - a * np.cos(theta), yc + a * np.cos(theta)), color='g', linewidth = 2)\n",
      "    \n",
      "        plt.plot((xc - b * np.cos(theta), xc + b * np.cos(theta)), \\\n",
      "                  (yc + b * np.sin(theta), yc - b * np.sin(theta)), color='m', linewidth =2)\n",
      "        imgCx, imgCy = (img_x-1)/2.0, (img_y-1)/2.0\n",
      "        plt.plot((xc, imgCx), (yc, imgCy), color = 'r', linewidth = 2)\n",
      "       \n",
      "    plt.subplot(122)  \n",
      "    plt.xlim(0, img_x)\n",
      "    plt.ylim(0, img_y)\n",
      "    plt.title('Identified Clusters')\n",
      "    plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Run on 12 objects\n",
      "\n",
      "Now I'll run these functions on a directory of objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#make sure to change this directory name on your machine.\n",
      "directory = '/home/mclaughlin6464/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/'\n",
      "filenames =os.listdir(directory)\n",
      "\n",
      "for filename in filenames:\n",
      "    residuals = makeResidualsDict(directory+filename)\n",
      "    if checkLens(residuals):\n",
      "        print '%s was identified as a lens.'%filename\n",
      "    else:\n",
      "        print '%s was NOT identified as a lens.'%filename\n",
      "    plotResiduals(residuals)\n",
      "    print '-'*100+'\\n\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "OSError",
       "evalue": "[Errno 2] No such file or directory: '/home/mclaughlin6464/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-5-bfd8f09cd74d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#make sure to change this directory name on your machine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/mclaughlin6464/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/home/mclaughlin6464/GitRepos/Bayesian_Image_Modeling/Fit_Many_Images/residualArrays/'"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3/12 faild to detect the lens. Not bad, but not great. I think the first 2 failed because the center was not properly identified in the image, because the center of the structure in those cases is not necessarily the center of the image. The last one fails becasue the distance from the center is 3.8, when the threshold is 3. I arbitrarily chose that threshold, so I could increase it."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}